{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"../datasets/penguins.csv\")\n",
    "\n",
    "feature_names = [\n",
    "    \"Culmen Length (mm)\",\n",
    "    \"Culmen Depth (mm)\",\n",
    "    \"Flipper Length (mm)\",\n",
    "]\n",
    "target_name = \"Body Mass (g)\"\n",
    "\n",
    "dataset = dataset[feature_names + [target_name]].dropna(axis=\"rows\", how=\"any\")\n",
    "dataset = dataset.sample(frac=1, random_state=0).reset_index(drop=True)\n",
    "data, target = dataset[feature_names], dataset[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "cv=10\n",
    "cv_results_tree = cross_validate(tree, data, target, cv=cv, return_train_score=True)\n",
    "cv_results_tree[\"test_score\"].mean(), cv_results_tree[\"test_score\"].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "cv_results_rf = cross_validate(rf, data, target, cv=cv, return_train_score=True)\n",
    "cv_results_rf[\"test_score\"].mean(), cv_results_rf[\"test_score\"].std() \n",
    "print(\n",
    "    \"Random forest is better than a single decision tree for \"\n",
    "    f\"{sum(cv_results_rf['test_score'] > cv_results_tree['test_score'])} \"\n",
    "    \"CV iterations out of 10\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_5_trees = RandomForestRegressor(n_estimators=5, random_state=0)\n",
    "rf_100_trees = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "\n",
    "cv_results_rf_5_trees = cross_validate(\n",
    "    rf_5_trees, data, target, cv=cv, return_train_score=True\n",
    ")\n",
    "cv_results_rf_100_trees = cross_validate(\n",
    "    rf_100_trees, data, target, cv=cv, return_train_score=True\n",
    ")\n",
    "print(\n",
    "    \"Random forest with 100 trees is better than a random forest with 5 trees for \"\n",
    "    f\"{sum(cv_results_rf_100_trees['test_score'] > cv_results_rf_5_trees['test_score'])} \"\n",
    "    \"CV iterations out of 10\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Scores for random forest with 5 trees: \"\n",
    "    f\"train: {cv_results_rf_5_trees['train_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results_rf_5_trees['train_score'].std():.3f}, \"\n",
    "    f\"test: {cv_results_rf_5_trees['test_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results_rf_5_trees['test_score'].std():.3f}\"\n",
    ")\n",
    "print(    \n",
    "    \"Scores for random forest with 100 trees: \"\n",
    "    f\"train: {cv_results_rf_100_trees['train_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results_rf_100_trees['train_score'].std():.3f}, \"\n",
    "    f\"test: {cv_results_rf_100_trees['test_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results_rf_100_trees['test_score'].std():.3f}\"\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import ValidationCurveDisplay\n",
    "\n",
    "n_estimators = np.array([1, 2, 5, 10, 20, 50, 100, 200, 500, 1_000])\n",
    "\n",
    "disp = ValidationCurveDisplay.from_estimator(\n",
    "    rf,\n",
    "    data,\n",
    "    target,\n",
    "    param_name=\"n_estimators\",\n",
    "    param_range=n_estimators,\n",
    "    scoring=\"r2\",  # this is already the default for regression\n",
    "    score_name=\"R2 score\",\n",
    "    std_display_style=\"errorbar\",\n",
    "    cv=cv,\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "_ = disp.ax_.set(\n",
    "    xlabel=\"Number of trees\",\n",
    "    title=\"Validation curve for Random Forest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1_tree = RandomForestRegressor(n_estimators=1, random_state=0)\n",
    "cv_results_tree = cross_validate(\n",
    "    rf_1_tree, data, target, cv=10, return_train_score=True\n",
    ")\n",
    "cv_results_tree[\"train_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "cv_results_tree = cross_validate(\n",
    "    tree, data, target, cv=10, return_train_score=True\n",
    ")\n",
    "cv_results_tree[\"train_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1_tree = RandomForestRegressor(n_estimators=1, bootstrap=False, random_state=0)\n",
    "cross_validate(rf_1_tree, data, target, cv=cv, return_train_score=True)[\"train_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "hgbdt = HistGradientBoostingRegressor(random_state=0)\n",
    "max_iters = np.array([1, 2, 5, 10, 20, 50, 100, 200, 500])\n",
    "\n",
    "disp = ValidationCurveDisplay.from_estimator(\n",
    "    hgbdt,\n",
    "    data,\n",
    "    target,\n",
    "    param_name=\"max_iter\",\n",
    "    param_range=max_iters,\n",
    "    scoring=\"r2\",  # note: this is already the default for regression\n",
    "    score_name=\"R2 score\",\n",
    "    std_display_style=\"errorbar\",\n",
    "    cv=cv,\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "_ = disp.ax_.set(\n",
    "    xlabel=\"(Maximum) number of trees\",\n",
    "    title=\"Validation curve for Histogram GBDT\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbdt = HistGradientBoostingRegressor(early_stopping=True, random_state=0)\n",
    "cv_results_hgbdt = cross_validate(\n",
    "    hgbdt, data, target, cv=cv, return_train_score=True, return_estimator=True\n",
    ")\n",
    "cv_results_hgbdt[\"train_score\"].mean(), cv_results_hgbdt[\"train_score\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_hgbdt[\"test_score\"].mean(), cv_results_hgbdt[\"test_score\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, est in enumerate(cv_results_hgbdt[\"estimator\"]):\n",
    "    print(\n",
    "        f\"For CV iteration {idx + 1}, {est.n_iter_} trees were built\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
