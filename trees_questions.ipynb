{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ames_housing = pd.read_csv(\n",
    "    \"../datasets/ames_housing_no_missing.csv\",\n",
    "    na_filter=False,  # required for pandas>2.0\n",
    ")\n",
    "target_name = \"SalePrice\"\n",
    "data = ames_housing.drop(columns=target_name)\n",
    "target = ames_housing[target_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\n",
    "    \"LotFrontage\", \"LotArea\", \"MasVnrArea\", \"BsmtFinSF1\", \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\", \"TotalBsmtSF\", \"1stFlrSF\", \"2ndFlrSF\", \"LowQualFinSF\",\n",
    "    \"GrLivArea\", \"BedroomAbvGr\", \"KitchenAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\",\n",
    "    \"GarageCars\", \"GarageArea\", \"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\",\n",
    "    \"3SsnPorch\", \"ScreenPorch\", \"PoolArea\", \"MiscVal\",\n",
    "]\n",
    "\n",
    "data_numerical = data[numerical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76129977, 0.80635105, 0.81358636, 0.66592199, 0.79964891,\n",
       "       0.76868787, 0.75635094, 0.71822127, 0.31479306, 0.78635221])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = make_pipeline(StandardScaler(), LinearRegression())\n",
    "cv_results_linear_regression = cross_validate(\n",
    "    linear_regression, data_numerical, target, cv=10, return_estimator=True,\n",
    "    n_jobs=2\n",
    ")\n",
    "scores_lr = cv_results_linear_regression[\"test_score\"]\n",
    "scores_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree = DecisionTreeRegressor(random_state=0)\n",
    "cv_results_tree = cross_validate(\n",
    "    tree, data_numerical, target, cv=10, n_jobs=2\n",
    ")\n",
    "score_tree = cv_results_tree[\"test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression is better than decision tree for 9 CV iterations out of 10 folds.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Linear regression is better than decision tree for \"\n",
    "    f\"{sum(scores_lr > score_tree)} CV iterations out of 10 folds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\"max_depth\": np.arange(1, 16)}\n",
    "search = GridSearchCV(tree, params, cv=10)\n",
    "cv_results_tree_optimal_depth = cross_validate(\n",
    "    search, data_numerical, target, cv=10, return_estimator=True, n_jobs=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for search_cv in cv_results_tree_optimal_depth[\"estimator\"]:\n",
    "    print(search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = GridSearchCV(tree, params, cv=10)\n",
    "cv_results_tree_optimal_depth = cross_validate(\n",
    "    search, data_numerical, target, cv=10, return_estimator=True, n_jobs=2,\n",
    ")\n",
    "cv_results_tree_optimal_depth[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"A tree with an optimized depth is better than linear regression for \"\n",
    "    f\"{sum(cv_results_tree_optimal_depth['test_score'] > scores_lr)} CV \"\n",
    "    \"iterations out of 10 folds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "categorical_processor = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (categorical_processor, selector(dtype_include=object)),\n",
    "    (\"passthrough\", numerical_features)\n",
    ")\n",
    "tree = make_pipeline(preprocessor, DecisionTreeRegressor(max_depth=7, random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(\n",
    "    tree, data, target, cv=10, return_estimator=True, n_jobs=2\n",
    ")\n",
    "cv_results[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_score_num = cv_results_tree_optimal_depth[\"test_score\"]\n",
    "test_score_all = cv_results[\"test_score\"]\n",
    "\n",
    "indices = np.arange(len(test_score_num))\n",
    "plt.scatter(\n",
    "    indices, test_score_num, color=\"tab:blue\", label=\"numerical features only\"\n",
    ")\n",
    "plt.scatter(\n",
    "    indices,\n",
    "    test_score_all,\n",
    "    color=\"tab:red\",\n",
    "    label=\"all features\",\n",
    ")\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel(\"Cross-validation iteration\")\n",
    "plt.ylabel(\"R2 score\")\n",
    "_ = plt.legend(loc=\"lower right\")\n",
    "\n",
    "print(\n",
    "    \"A tree model using both numerical and categorical features is better than a \"\n",
    "    \"tree with optimal depth using only numerical features for \"\n",
    "    f\"{sum(cv_results['test_score'] > cv_results_tree_optimal_depth['test_score'])} CV \"\n",
    "    \"iterations out of 10 folds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
